{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow_probability import edward2 as ed\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_regression(n_samples=1000000, n_features=10, n_informative=7)\n",
    "\n",
    "hparams = tf.contrib.training.HParams(test_size=0.2, batch_size=100, shuffle_iterations=1000, learning_rate=0.05,\n",
    "                                     num_posterior_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(x, y, phase, hparams):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=hparams.test_size)\n",
    "    \n",
    "    if phase == 'train':\n",
    "        x_tensor = tf.convert_to_tensor(x_train, tf.float32)\n",
    "        y_tensor = tf.convert_to_tensor(y_train, tf.float32)\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "        shuffle = dataset.shuffle(hparams.shuffle_iterations)\n",
    "        batches = shuffle.repeat().batch(hparams.batch_size)\n",
    "        iterator = batches.make_one_shot_iterator()\n",
    "        features, label = iterator.get_next()\n",
    "        \n",
    "        return features, label\n",
    "    else:\n",
    "        x_tensor = tf.convert_to_tensor(x_test, tf.float32)\n",
    "        y_tensor = tf.convert_to_tensor(y_test, tf.float32)\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "        shuffle = dataset.shuffle(hparams.shuffle_iterations)\n",
    "        batches = shuffle.repeat().batch(hparams.batch_size)\n",
    "        iterator = batches.make_one_shot_iterator()\n",
    "        features, label = iterator.get_next()\n",
    "        \n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(object):\n",
    "    def __init__(self):\n",
    "        self.hparams = hparams\n",
    "        self.weights_dict = {'w':None, 'b':None}\n",
    "    \n",
    "    def fit(self, input_fn):\n",
    "        \n",
    "        features, label = input_fn()\n",
    "\n",
    "        def linear_model(X): # (unmodeled) data\n",
    "            w = ed.Normal(loc=tf.zeros([X.shape[1]]),\n",
    "                scale=tf.ones([X.shape[1]]),\n",
    "                name=\"w\")  # parameter\n",
    "            b = ed.Normal(loc=tf.zeros([]),\n",
    "                scale=tf.ones([]), \n",
    "                name=\"b\")  # parameter\n",
    "            y = ed.Normal(loc=tf.tensordot(X, w, axes=1) + b, scale=1.0, \n",
    "                name=\"y\")  # (modeled) data\n",
    "            return y   \n",
    "\n",
    "        def variational_model(qw_mean, qw_stddv, qb_mean, qb_stddv):\n",
    "            qw = ed.Normal(loc=qw_mean, scale=qw_stddv, name=\"qw\")\n",
    "            qb = ed.Normal(loc=qb_mean, scale=qb_stddv, name=\"qb\")          \n",
    "            return qw, qb\n",
    "\n",
    "        log_q = ed.make_log_joint_fn(variational_model)\n",
    "\n",
    "        def target_q(qw, qb):\n",
    "            return log_q(qw_mean=qw_mean, qw_stddv=qw_stddv, qb_mean=qb_mean, qb_stddv=qb_stddv, qw=qw, qb=qb)\n",
    "\n",
    "        qw_mean = tf.Variable(tf.zeros([int(features.shape[1])]), dtype=tf.float32)\n",
    "        qb_mean = tf.Variable(tf.zeros([]), dtype=tf.float32)\n",
    "        qw_stddv = tf.nn.softplus(tf.Variable(tf.ones([int(features.shape[1])]), dtype=tf.float32))\n",
    "        qb_stddv = tf.nn.softplus(tf.Variable(tf.ones([]), dtype=tf.float32))\n",
    "\n",
    "        qw, qb = variational_model(qw_mean=qw_mean, qw_stddv=qw_stddv,\n",
    "                                qb_mean=qb_mean, qb_stddv=qb_stddv)\n",
    "\n",
    "        log_joint = ed.make_log_joint_fn(linear_model)\n",
    "\n",
    "        def target(qw, qb):\n",
    "            \"\"\"Unnormalized target density as a function of the parameters.\"\"\"\n",
    "            return log_joint(w=qw, b=qb, X=features, y=label)\n",
    "\n",
    "        energy = target(qw, qb) \n",
    "        entropy = -target_q(qw, qb) / hparams.batch_size\n",
    "        elbo = energy + entropy\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = hparams.learning_rate)\n",
    "        train = optimizer.minimize(-elbo)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        t = []\n",
    "        n_rows = int(x.shape[0] * (1-hparams.test_size))\n",
    "        num_steps = int(n_rows / hparams.batch_size)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "            for step in range(num_steps):\n",
    "                _ = sess.run([train])\n",
    "                if step % 100 == 0:\n",
    "                    t.append(sess.run([elbo]))\n",
    "            \n",
    "            self.weights_dict['w'], self.weights_dict['b'] = sess.run([qw.distribution.sample(hparams.num_posterior_samples), \n",
    "                                                             qb.distribution.sample(hparams.num_posterior_samples)])\n",
    "\n",
    "    def evaluate(self, input_fn):\n",
    "\n",
    "        features, label = input_fn()\n",
    "\n",
    "        w_ = tf.reduce_mean(self.weights_dict['w'], 0)\n",
    "        b_ = tf.reduce_mean(self.weights_dict['b'], 0)\n",
    "\n",
    "        predictions = tf.cast((tf.tensordot(features, w_, axes=1) + b_), tf.float32)\n",
    "\n",
    "        rmse, rmse_update_op = tf.metrics.root_mean_squared_error(tf.cast(label,tf.float32), predictions)\n",
    "\n",
    "        n_rows = int(x.shape[0] * (hparams.test_size))\n",
    "        n_batches = int(n_rows / hparams.batch_size)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            for _i in range(n_batches):\n",
    "                rmse_ = sess.run([rmse_update_op])\n",
    "\n",
    "            metrics = {}\n",
    "            metrics[\"rmse\"] = sess.run([rmse])\n",
    "            return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_toy_regression = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = lambda:input_data(x, y, 'train', hparams)\n",
    "test_input_fn = lambda:input_data(x, y, 'test', hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allenchang/PycharmProjects/tf_probability/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "predict_toy_regression.fit(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allenchang/PycharmProjects/tf_probability/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': [1.9667388]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_toy_regression.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
