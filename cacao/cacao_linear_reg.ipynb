{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from edward.models import Normal, Bernoulli\n",
    "\n",
    "import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './flavors_of_cacao.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allenchang/PycharmProjects/edward_one/cacao/preprocess_data.py:53: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  np.logical_or(cacao['species'].str.lower().str.contains(',|(blend)|;'),\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = preprocess_data.preprocess_data(file_path, test_pct=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_train.shape[0]  # Number of rows in training data\n",
    "D = x_train.shape[1]  # Number of columns in training data\n",
    "M = 32  # Mini-batch size\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32, [None, D])  # Placeholder variable for x data\n",
    "y_ph = tf.placeholder(tf.float32, [None])  # Placeholder variable for y data \n",
    "\n",
    "w = Normal(loc=tf.zeros(D), scale=tf.ones(D))  # Weights prior\n",
    "b = Normal(loc=tf.zeros(1.), scale=tf.ones(1.))  # Bias prior\n",
    "y = Normal(loc=ed.dot(x_ph, w) + b, scale=1.0)  # Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = Normal(loc=tf.get_variable('qw/loc', [D]),\n",
    "            scale=tf.nn.softplus(tf.get_variable('qw/scale', [D])))  # Inferred parameter\n",
    "qb = Normal(loc=tf.get_variable('qb/loc', [1]),\n",
    "            scale=tf.nn.softplus(tf.get_variable('qb/scale', [1])))  # Inferred parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(arrays, batch_size):\n",
    "  \"\"\"Generate batches, one with respect to each array's first axis.\"\"\"\n",
    "  starts = [0] * len(arrays)  # pointers to where we are in iteration\n",
    "  while True:\n",
    "    batches = []\n",
    "    for i, array in enumerate(arrays):\n",
    "      start = starts[i]\n",
    "      stop = start + batch_size\n",
    "      diff = stop - array.shape[0]\n",
    "      if diff <= 0:\n",
    "        batch = array[start:stop]\n",
    "        starts[i] += batch_size\n",
    "      else:\n",
    "        batch = np.concatenate((array[start:], array[:diff]))\n",
    "        starts[i] = diff\n",
    "      batches.append(batch)\n",
    "    yield batches\n",
    "\n",
    "data = generator([x_train, y_train], M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = int(N / M)\n",
    "n_epoch = 5\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={y: y_ph})\n",
    "inference.initialize(\n",
    "    n_iter=n_batch * n_epoch, n_samples=10, scale={y: N / M}, logdir='log')\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [100%] ██████████████████████████████ Elapsed: 4s | Loss: 3622.374\n"
     ]
    }
   ],
   "source": [
    "for _ in range(inference.n_iter):\n",
    "    X_batch, y_batch = next(data)\n",
    "    info_dict = inference.update({x_ph:X_batch, y_ph: y_batch})\n",
    "    inference.print_progress(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_post = ed.copy(y, {w: qw, b: qb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allenchang/PycharmProjects/edward_one/venv/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8846741\n",
      "Mean absolute error on test data:\n",
      "1.1492201\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={x_ph: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={x_ph: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!tensorboard --logdir=20181001_161900"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
