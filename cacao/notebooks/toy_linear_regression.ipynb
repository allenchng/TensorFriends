{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from edward.models import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make toy data\n",
    "\n",
    "X, y = make_regression(n_samples=500000, n_features = 20, n_informative=15)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_train.shape[0]\n",
    "D = x_train.shape[1]\n",
    "M = 50\n",
    "\n",
    "# set up placeholders\n",
    "x_ph = tf.placeholder(tf.float32, [None, D])\n",
    "y_ph = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "w = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "b = Normal(loc=tf.zeros(1.), scale=tf.ones(1.))\n",
    "y = Normal(loc=ed.dot(x_ph, w) + b, scale=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = Normal(loc=tf.get_variable('qw/loc', [D]),\n",
    "            scale=tf.nn.softplus(tf.get_variable('qw/scale', [D])))\n",
    "qb = Normal(loc=tf.get_variable('qb/loc', [1]),\n",
    "            scale=tf.nn.softplus(tf.get_variable('qb/scale', [1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(arrays, batch_size):\n",
    "  \"\"\"Generate batches, one with respect to each array's first axis.\"\"\"\n",
    "  starts = [0] * len(arrays)  # pointers to where we are in iteration\n",
    "  while True:\n",
    "    batches = []\n",
    "    for i, array in enumerate(arrays):\n",
    "      start = starts[i]\n",
    "      stop = start + batch_size\n",
    "      diff = stop - array.shape[0]\n",
    "      if diff <= 0:\n",
    "        batch = array[start:stop]\n",
    "        starts[i] += batch_size\n",
    "      else:\n",
    "        batch = np.concatenate((array[start:], array[:diff]))\n",
    "        starts[i] = diff\n",
    "      batches.append(batch)\n",
    "    yield batches\n",
    "\n",
    "data = generator([x_train, y_train], M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = int(N / M)\n",
    "n_epoch = 5\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={y: y_ph})\n",
    "inference.initialize(\n",
    "    n_iter=n_batch * n_epoch, n_samples=10, scale={y: N / M}, logdir='log')\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [100%] ██████████████████████████████ Elapsed: 112s | Loss: 115042832.000\n"
     ]
    }
   ],
   "source": [
    "for _ in range(inference.n_iter):\n",
    "    X_batch, y_batch = next(data)\n",
    "    info_dict = inference.update({x_ph:X_batch, y_ph: y_batch})\n",
    "    inference.print_progress(info_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_post = ed.copy(y, {w: qw, b: qb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allenchang/PycharmProjects/edward_one/venv/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637.9396\n",
      "Mean absolute error on test data:\n",
      "20.15033\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={x_ph: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={x_ph: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.6.0 at http://Allens-MacBook-Pro.local:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=20181001_161900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
